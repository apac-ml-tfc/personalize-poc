{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Up\n",
    "\n",
    "This notebook demonstrates how to clean up all the resources created in this set of PoC notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # (AWS Python SDK)\n",
    "\n",
    "%store -r\n",
    "\n",
    "# If any of these variables aren't recovered by the %store, you'll need to find and set them for this cleanup\n",
    "# to work:\n",
    "print(f\"Dataset Group: {dataset_group_arn}\")\n",
    "print(f\"S3 Bucket: {bucket_name}\")\n",
    "print(f\"IAM Role: {personalize_role_arn}\")\n",
    "\n",
    "# Connect to Personalize API:\n",
    "personalize = boto3.client(\"personalize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note some steps rely on previous resource types being fully deleted before they can proceed. If you receive an error, wait a minute or two and try again.\n",
    "\n",
    "## Clean up Campaigns\n",
    "\n",
    "⚠️ This section will DELETE **all campaigns within the dataset_group_arn you configured above**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = personalize.list_solutions(\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    # NOTE: You will need to take additional steps in the (very unlikely!) event you have more than 100\n",
    "    # solutions in this dataset group:\n",
    "    maxResults=100,\n",
    ")[\"solutions\"]\n",
    "\n",
    "any_campaigns_deleted = False\n",
    "\n",
    "for solution in solutions:\n",
    "    solution_arn = solution[\"solutionArn\"]\n",
    "    campaigns = personalize.list_campaigns(solutionArn=solution_arn)[\"campaigns\"]\n",
    "    for campaign in campaigns:\n",
    "        campaign_arn = campaign[\"campaignArn\"]\n",
    "        print(f\"DELETING CAMPAIGN {campaign_arn}\")\n",
    "        personalize.delete_campaign(campaignArn=campaign_arn)\n",
    "        any_campaigns_deleted = True\n",
    "        time.sleep(.2)\n",
    "\n",
    "if any_campaigns_deleted:\n",
    "    print(f\"WAITING 4 minutes for campaign deletions to propagate\")\n",
    "    time.sleep(60 * 4)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up Event Trackers\n",
    "\n",
    "⚠️ This section will DELETE **all event trackers within the dataset_group_arn you configured**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackers = personalize.list_event_trackers(\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    # NOTE: You will need to take additional steps in the (very unlikely!) event you have more than 100\n",
    "    # trackers in this dataset group:\n",
    "    maxResults=100,\n",
    ")[\"eventTrackers\"]\n",
    "\n",
    "for tracker in trackers:\n",
    "    tracker_arn = tracker[\"eventTrackerArn\"]\n",
    "    print(f\"DELETING EVENT TRACKER {tracker_arn}\")\n",
    "    personalize.delete_event_tracker(eventTrackerArn=tracker_arn)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "if len(trackers):\n",
    "    print(f\"WAITING 30s for tracker deletions to propagate\")\n",
    "    time.sleep(30)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up Filters\n",
    "\n",
    "⚠️ This section will DELETE **all filters within the dataset_group_arn you configured**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = personalize.list_filters(\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    # NOTE: You will need to take additional steps in the (very unlikely!) event you have more than 100\n",
    "    # filters in this dataset group:\n",
    "    maxResults=100,\n",
    ")[\"Filters\"]\n",
    "\n",
    "for f in filters:\n",
    "    filter_arn = f[\"filterArn\"]\n",
    "    print(f\"DELETING FILTER {filter_arn}\")\n",
    "    personalize.delete_filter(filterArn=filter_arn)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "if len(trackers):\n",
    "    print(f\"WAITING 30s for filter deletions to propagate\")\n",
    "    time.sleep(30)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up Solutions\n",
    "\n",
    "⚠️ This section will DELETE **all solutions within the dataset_group_arn you configured**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = personalize.list_solutions(\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    # NOTE: You will need to take additional steps in the (very unlikely!) event you have more than 100\n",
    "    # solutions in this dataset group:\n",
    "    maxResults=100,\n",
    ")[\"solutions\"]\n",
    "\n",
    "for solution in solutions:\n",
    "    solution_arn = solution[\"solutionArn\"]\n",
    "    #solnvers = personalize.list_solution_versions(solutionArn=solution_arn)[\"solutionVersions\"]\n",
    "    print(f\"DELETING SOLUTION {solution_arn}\")\n",
    "    personalize.delete_solution(solutionArn=solution_arn)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "if len(solutions):\n",
    "    print(f\"WAITING 120s for solution deletions to propagate\")\n",
    "    time.sleep(120)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up Datasets and Schemas\n",
    "\n",
    "⚠️ This section will DELETE:\n",
    "\n",
    "- **All datasets within the dataset_group_arn you configured**\n",
    "- **Any schemas not also used by other dataset groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = personalize.list_datasets(datasetGroupArn=dataset_group_arn)[\"datasets\"]\n",
    "\n",
    "schema_arns = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset_arn = dataset[\"datasetArn\"]\n",
    "    schema_arns.append(personalize.describe_dataset(datasetArn=dataset_arn)[\"dataset\"][\"schemaArn\"])\n",
    "    print(f\"DELETING DATASET {dataset_arn}\")\n",
    "    personalize.delete_dataset(datasetArn=dataset_arn)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "if len(datasets):\n",
    "    print(f\"WAITING 60s for dataset deletions to propagate\")\n",
    "    time.sleep(60)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_schemas_deleted = False\n",
    "\n",
    "for schema_arn in schema_arns:\n",
    "    try:\n",
    "        print(f\"DELETING SCHEMA {schema_arn}\")\n",
    "        personalize.delete_schema(schemaArn=schema_arn)\n",
    "        any_schemas_deleted = True\n",
    "        time.sleep(0.2)\n",
    "    except personalize.exceptions.ResourceNotFoundException:\n",
    "        print(f\"(already deleted)\")\n",
    "    except personalize.exceptions.ResourceInUseException as e:\n",
    "        print(f\"###### WARNING - Failed to delete schema - appears to be in-use by another dataset\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "if any_schemas_deleted:\n",
    "    print(f\"WAITING 60s for schema deletions to propagate\")\n",
    "    time.sleep(60)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the Dataset Group\n",
    "\n",
    "Finally, clean up the empty dataset group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.delete_dataset_group(datasetGroupArn=dataset_group_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the S3 bucket and IAM role\n",
    "\n",
    "Start by deleting the role, then empty the bucket, then delete the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the name of the role you want to delete.\n",
    "\n",
    "You cannot delete an IAM role which still has policies attached to it. So after you have identified the relevant role, let's list the attached policies of that role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = personalize_role_arn.partition(\"/\")[2]\n",
    "\n",
    "iam.list_attached_role_policies(RoleName=role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to detach the policies in the result above using the code below. Repeat for each attached policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.detach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn=\"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.detach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3FullAccess\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you should be able to delete the IAM role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.delete_role(RoleName=role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete an S3 bucket, it first needs to be empty. The safest way to delete an S3 bucket, is just to navigate to S3 in the AWS console, delete the objects in the bucket, and then delete the S3 bucket itself... The code below will also work, but be **very careful** about what buckets you point it at!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"DELETING s3://{bucket_name}\")\n",
    "# time.sleep(5)\n",
    "# !aws s3 rm --recursive s3://$bucket_name\n",
    "\n",
    "# boto3.resource(\"s3\").Bucket(bucket_name).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All done!\n",
    "\n",
    "Thanks for following along! For more resources on Amazon Personalize, check out the [official samples repository](https://github.com/aws-samples/amazon-personalize-samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
